[
  {
    "objectID": "starter-analysis-exercise/starter-analysis-exercise.html",
    "href": "starter-analysis-exercise/starter-analysis-exercise.html",
    "title": "Future Exercise",
    "section": "",
    "text": "library(\"dslabs\")\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\ndata(gapminder)\n\nafricadata &lt;- subset(gapminder, (continent == \"Africa\"))\n#creates a new dataframe from a subset of the old one where the continent is Africa\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n#Checks to make sure I have the correct number of observations\n\ninf_LE &lt;- data.frame(africadata$infant_mortality, africadata$life_expectancy)\n#creates a new dataframe from these two columns of the africadata dataframe\n#this one is for infant mortality and Life expectancy\nstr(inf_LE)\n\n'data.frame':   2907 obs. of  2 variables:\n $ africadata.infant_mortality: num  148 208 187 116 161 ...\n $ africadata.life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\n#This checks to make sure I got it right\n\npop_LE &lt;- data.frame(africadata$population, africadata$life_expectancy)\n#This creates a new dataframe for population and life expectancy data\nstr(pop_LE)\n\n'data.frame':   2907 obs. of  2 variables:\n $ africadata.population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ africadata.life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\n#This checks that I have everything right\n\nplot(inf_LE)\n\n\n\n\n\n\n\n#plots this dataframe on a scatter plot\n#plot(pop_LE$africadata.population, pop_LE$africadata.life_expectancy, log = \"x\")\n#above is one option for generating the other scatter plot\nplot(pop_LE, log = \"x\")\n\n\n\n\n\n\n\n#here is a neater version\n#the log function is where you can specify which axis should be in log, in this case population\n\nMy hypothesis for the streaks of data we see is that they are individual countries over time\n\nyear_inf &lt;- data.frame(africadata$year, africadata$infant_mortality)\n#this creates a matrix with year and infant mortality\nyear_inf[is.na(year_inf)] &lt;- \"A\"\n#this line rewrites the dataset, changing all NA's to A\nmissing &lt;- subset(year_inf, (africadata.infant_mortality == \"A\"))\n#this makes a new dataset with the subset function that pulls out all the years with A as a value\n#This didn't work with NA which is why I changed it to A. Not the most elegant solution but it works\nstr(missing)\n\n'data.frame':   226 obs. of  2 variables:\n $ africadata.year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ africadata.infant_mortality: chr  \"A\" \"A\" \"A\" \"A\" ...\n\n#this line is for checking\n\nyear2000 &lt;- subset(africadata, (year == \"2000\"))\n#this creates a new data.frame with all the data from the year 2000 from africadata\nstr(year2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n#this is for checking\n\nplot(year2000$infant_mortality, year2000$life_expectancy)\n\n\n\n\n\n\n\nplot(year2000$population, year2000$life_expectancy, log = \"x\")\n\n\n\n\n\n\n\n\nThese are the updated plots for the year 2000!\n\nfit1 &lt;- lm(year2000$life_expectancy ~ year2000$infant_mortality)\nsummary(fit1)\n\n\nCall:\nlm(formula = year2000$life_expectancy ~ year2000$infant_mortality)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               71.29331    2.42611  29.386  &lt; 2e-16 ***\nyear2000$infant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\nfit2 &lt;- lm(year2000$life_expectancy ~ year2000$population)\nsummary(fit2)\n\n\nCall:\nlm(formula = year2000$life_expectancy ~ year2000$population)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.429  -4.602  -2.568   3.800  18.802 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.593e+01  1.468e+00  38.097   &lt;2e-16 ***\nyear2000$population 2.756e-08  5.459e-08   0.505    0.616    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.524 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\n\n\nI used the help command to figure out what I needed to input into the lm command. It said the format was response ~ predictor. It also looked like I could set several responses and predictors.\nThis section is contributed by KATHERINELORUSSO\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nstr(us_contagious_diseases)\n\n'data.frame':   16065 obs. of  6 variables:\n $ disease        : Factor w/ 7 levels \"Hepatitis A\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ state          : Factor w/ 51 levels \"Alabama\",\"Alaska\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ year           : num  1966 1967 1968 1969 1970 ...\n $ weeks_reporting: num  50 49 52 49 51 51 45 45 45 46 ...\n $ count          : num  321 291 314 380 413 378 342 467 244 286 ...\n $ population     : num  3345787 3364130 3386068 3412450 3444165 ...\n\n#str function was used to see how many observations and variables (16065 observations & 6 variables)\nsummary(us_contagious_diseases)\n\n        disease            state            year      weeks_reporting\n Hepatitis A:2346   Alabama   :  315   Min.   :1928   Min.   : 0.00  \n Measles    :3825   Alaska    :  315   1st Qu.:1950   1st Qu.:31.00  \n Mumps      :1785   Arizona   :  315   Median :1975   Median :46.00  \n Pertussis  :2856   Arkansas  :  315   Mean   :1971   Mean   :37.38  \n Polio      :2091   California:  315   3rd Qu.:1990   3rd Qu.:50.00  \n Rubella    :1887   Colorado  :  315   Max.   :2011   Max.   :52.00  \n Smallpox   :1275   (Other)   :14175                                 \n     count          population      \n Min.   :     0   Min.   :   86853  \n 1st Qu.:     7   1st Qu.: 1018755  \n Median :    69   Median : 2749249  \n Mean   :  1493   Mean   : 4107584  \n 3rd Qu.:   525   3rd Qu.: 4996229  \n Max.   :132342   Max.   :37607525  \n                  NA's   :214       \n\n#summary was used to view the variables and statistical values of the variables. \n\nGAmumps &lt;- subset(us_contagious_diseases,state == \"Georgia\" & disease == \"Mumps\")\n#I wanted to only look at Georgia & Mumps data, so I used the filter function and named it GAdmumps.\nGAmumps2 &lt;- data.frame(GAmumps$year, GAmumps$count)\n#I then created a dataset of year and count for mumps. \nsummary(GAmumps2)\n\n  GAmumps.year  GAmumps.count  \n Min.   :1968   Min.   :  1.0  \n 1st Qu.:1976   1st Qu.:  6.0  \n Median :1985   Median : 18.0  \n Mean   :1985   Mean   : 29.2  \n 3rd Qu.:1994   3rd Qu.: 38.5  \n Max.   :2002   Max.   :103.0  \n\nGAmeasles &lt;- subset(us_contagious_diseases,state == \"Georgia\" & disease == \"Measles\")\n#I wanted to only look at Georgia & Measles data, so I used the filter function and named it GAmeasles.\nGAmeasles2 &lt;- data.frame(GAmeasles$year, GAmeasles$count)\n#I then created a dataset of year and count for mumps. \nsummary(GAmeasles2)\n\n GAmeasles.year GAmeasles.count  \n Min.   :1928   Min.   :    0.0  \n 1st Qu.:1946   1st Qu.:    6.5  \n Median :1965   Median :  244.0  \n Mean   :1965   Mean   : 2073.1  \n 3rd Qu.:1984   3rd Qu.: 3215.0  \n Max.   :2002   Max.   :22965.0  \n\nplot(GAmumps2)\n\n\n\n\n\n\n\n#This plot shows an increase from 1970-1989, a spike in 1990, then a decrease. \nplot(GAmeasles2)\n\n\n\n\n\n\n\n#this plot shows a significant decrease in cases after 1960. \nyear_measles &lt;- subset(us_contagious_diseases, (year==\"1934\" & disease==\"Measles\"))\n#I now used the subset function to only look at measles cases from 2000\nplot(year_measles$count, year_measles$population)\n\n\n\n\n\n\n\n#I plotted count of measles cases on the x axis and population of each state on the y axis. \nfit1 &lt;- lm(year_measles$population ~ year_measles$count)\nsummary(fit1)\n\n\nCall:\nlm(formula = year_measles$population ~ year_measles$count)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3852283  -829103  -189625   484704  8305549 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        909749.73  346349.07   2.627   0.0116 *  \nyear_measles$count    113.08      15.57   7.264 3.25e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1806000 on 47 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5289,    Adjusted R-squared:  0.5189 \nF-statistic: 52.77 on 1 and 47 DF,  p-value: 3.254e-09\n\n#There is a significant positive correlation between population and measles count in 1934."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About Esther",
    "section": "",
    "text": "Background\nI grew up in Northern Virginia and recieved by B.S. in Microbiology from Virginia Tech in 2023. I currently research Salmonella in water, and ask questions like: How does Salmonella get into water? How does Salmonella move through a creek? How long does Salmonella stay in a creek? and What adaptations do different serovars of Salmonella use to survive in water?\nI have a particular interest in microbial genomics and transcriptomics. I have done some analysis of RNA-seq data, and some genomic analysis from Whole Genome Sequencing.\nIn this course I hope to learn about tools for processing large data sets and more bioinformatics skills.\nOne interesting thing about me is that I am well known for my terrible puns. \nTn-seq This is a video about the use of Tn-seq in Rhodobacter that does a good job describing how a Tn-seq dataset is generated. I plan on doing something similar soon for my research in Salmonella in order to determine what genes are essential for survival in water."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Esther Palmer’s website and data analysis portfolio",
    "section": "",
    "text": "Hello\nWelcome to my website and data analysis portfolio.\n\nPlease use the Menu Bar above to look around.\nHave fun!"
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Complex Data analysis",
    "section": "",
    "text": "I ran a Jaccard analysis on a set of Data of mine looking at Salmonella populations at 3 creek sites. I went sampling after it had been dry for 3 days, and also after rain. I want to know if the populations differ signifigantly between the wet/dry samplings. A Jaccard analysis measures beta diversity and compares every sample to every other sample producing essentially, a triangular matrix. I have been procrastinating on figureing out how to analyze and present this data for several months, so we’re doing it now. Based on some readings I have done, the typical test for something like this is a PERMANOVA. My current plan: load my matrix, load a thing denotating which samples are dry/wet, then figure out how to use these vectors and the matrix for the PERMANOVA. I hope this counts as complex data.\nLoad Libraries\n\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(here) #to set paths\n\nhere() starts at C:/Users/esthe/Documents/GitHub/EstherPalmer-portfolio\n\nlibrary(vegan) #this is a package that allows me to do a PERMANOVA I think\n\nLoading required package: permute\n\n\nThis loads all the libraries I need for this project\nLoad Data\n\ndata_location &lt;- here::here(\"data-exercise\", \"CC_CSS_Jaccard2.csv\")\njmatrix &lt;- read.csv(data_location, row.names = 1)\n#note to future self, do not populate row.names with the () version, use row.names = for it to work\n\nThis cell loads the output of my Jaccard analysis Note: I still need to redo the Jaccard with the last of my CSS files, so this is not final data.\nLoad Vectors\n\ndry.wet_location &lt;- here::here(\"data-exercise\", \"Samples_wet_dry.csv\")\ndry.wet &lt;- read.csv(dry.wet_location, header = TRUE)\n\nThis cell loads a file that denotes which samples are wet or dry\n\nresult &lt;- adonis2(jmatrix ~ Wet.Dry, dry.wet, permutations = 999, method = \"jaccard\")\n#this should run the permanova test using the adonis2 formula in the vegan package\nprint(result)\n\nPermutation test for adonis under reduced model\nPermutation: free\nNumber of permutations: 999\n\nadonis2(formula = jmatrix ~ Wet.Dry, data = dry.wet, permutations = 999, method = \"jaccard\")\n         Df SumOfSqs      R2     F Pr(&gt;F)   \nModel     1   0.5476 0.02781 2.718  0.008 **\nResidual 95  19.1388 0.97219                \nTotal    96  19.6864 1.00000                \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nI did something! I have no idea what the printed result fully means though. It looks like it might be signifigant? Theoretically this should compare all the wet samplings against all the dry samplings and see if there’s significant differences between the two groups."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html",
    "href": "cdcdata-exercise/cdcdata-exercise.html",
    "title": "CDC Data analysis",
    "section": "",
    "text": "I downloaded data from the BEAM dashboard (found here: https://data.cdc.gov/Foodborne-Waterborne-and-Related-Diseases/BEAM-Dashboard-Serotypes-of-concern-Illnesses-and-/fvm6-ic5r/about_data) I specifically filtered for data from year_first_ill is &gt; 2020 so there should be about 5 years of data.\nNow to lead in my packages:\n\nlibrary(here) #to set paths\n\nhere() starts at /Users/rebeccabasta/Desktop/EstherPalmer-portfolio\n\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(eeptools) #I need to remove commas and this is the easiest way I found\n\nLoading required package: ggplot2\n\nlibrary(ggplot2) #plots!\n\nNow to load in my data:\n\ndata_location &lt;- here::here(\"cdcdata-exercise\", \"BEAM_Dashboard_Data.csv\")\nBEAM &lt;- read.csv(data_location)\n\nNow to get a glimpse of my data:\n\nsummary(BEAM)\n\n   table_id         Food_category      Year_first_ill       Serotype        \n Length:339         Length:339         Length:339         Length:339        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n No_of_illnesses   No_of_outbreaks    Pathogen             Year          \n Min.   :  0.000   Min.   :0.0000   Length:339         Length:339        \n 1st Qu.:  0.000   1st Qu.:0.0000   Class :character   Class :character  \n Median :  0.000   Median :0.0000   Mode  :character   Mode  :character  \n Mean   :  5.752   Mean   :0.1888                                        \n 3rd Qu.:  0.000   3rd Qu.:0.0000                                        \n Max.   :181.000   Max.   :4.0000                                        \n  Year_range        Running_total_by_year_range\n Length:339         Min.   :  0.00             \n Class :character   1st Qu.:  0.00             \n Mode  :character   Median :  0.00             \n                    Mean   : 38.68             \n                    3rd Qu.: 29.00             \n                    Max.   :679.00             \n\nglimpse(BEAM)\n\nRows: 339\nColumns: 10\n$ table_id                    &lt;chr&gt; \"Pork_Adelaide_2017-2021\", \"Pork_Agona_201…\n$ Food_category               &lt;chr&gt; \"Pork\", \"Pork\", \"Chicken\", \"Turkey\", \"Pork…\n$ Year_first_ill              &lt;chr&gt; \"2,021\", \"2,021\", \"2,021\", \"2,021\", \"2,021…\n$ Serotype                    &lt;chr&gt; \"Adelaide\", \"Agona\", \"Anatum\", \"Anatum\", \"…\n$ No_of_illnesses             &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0,…\n$ No_of_outbreaks             &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ Pathogen                    &lt;chr&gt; \"Salmonella\", \"Salmonella\", \"Salmonella\", …\n$ Year                        &lt;chr&gt; \"2,021\", \"2,021\", \"2,021\", \"2,021\", \"2,021…\n$ Year_range                  &lt;chr&gt; \"2017-2021\", \"2017-2021\", \"2017-2021\", \"20…\n$ Running_total_by_year_range &lt;int&gt; 48, 0, 4, 8, 30, 146, 11, 80, 0, 0, 0, 0, …\n\nskim(BEAM)\n\n\nData summary\n\n\nName\nBEAM\n\n\nNumber of rows\n339\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n7\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntable_id\n0\n1\n20\n32\n0\n178\n0\n\n\nFood_category\n0\n1\n4\n7\n0\n4\n0\n\n\nYear_first_ill\n0\n1\n5\n5\n0\n3\n0\n\n\nSerotype\n0\n1\n5\n14\n0\n36\n0\n\n\nPathogen\n0\n1\n10\n10\n0\n1\n0\n\n\nYear\n0\n1\n5\n5\n0\n3\n0\n\n\nYear_range\n0\n1\n9\n9\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nNo_of_illnesses\n0\n1\n5.75\n23.54\n0\n0\n0\n0\n181\n▇▁▁▁▁\n\n\nNo_of_outbreaks\n0\n1\n0.19\n0.58\n0\n0\n0\n0\n4\n▇▁▁▁▁\n\n\nRunning_total_by_year_range\n0\n1\n38.68\n100.92\n0\n0\n0\n29\n679\n▇▁▁▁▁\n\n\n\n\n\nThere are 339 observations of 10 variables. Some of these variables probably shouldn’t be characters like Year. Some of these categories also feel unnessesary, like table_id which looks like it just contains info from several other columns. Also Pathogen should be Salmonella for all of this data, so it is unhelpful (and we can see there is only one observation). It does look like there’s no missing data though. There are 36 unique serovars which is cool!\nLets remove the useless variables\n\nd1 &lt;- data.frame(BEAM$Food_category, BEAM$Year_first_ill, BEAM$Serotype, BEAM$No_of_illnesses, BEAM$No_of_outbreaks, BEAM$Year, BEAM$Year_range, BEAM$Running_total_by_year_range )\nskim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n339\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nBEAM.Food_category\n0\n1\n4\n7\n0\n4\n0\n\n\nBEAM.Year_first_ill\n0\n1\n5\n5\n0\n3\n0\n\n\nBEAM.Serotype\n0\n1\n5\n14\n0\n36\n0\n\n\nBEAM.Year\n0\n1\n5\n5\n0\n3\n0\n\n\nBEAM.Year_range\n0\n1\n9\n9\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nBEAM.No_of_illnesses\n0\n1\n5.75\n23.54\n0\n0\n0\n0\n181\n▇▁▁▁▁\n\n\nBEAM.No_of_outbreaks\n0\n1\n0.19\n0.58\n0\n0\n0\n0\n4\n▇▁▁▁▁\n\n\nBEAM.Running_total_by_year_range\n0\n1\n38.68\n100.92\n0\n0\n0\n29\n679\n▇▁▁▁▁\n\n\n\n\n\n#Note to future self: this renames the variables to BEAM.variable\nLets turn the year into a numeric variable\n\nd1$BEAM.Year &lt;- decomma(d1$BEAM.Year)\nglimpse(d1$BEAM.Year)\n\n num [1:339] 2021 2021 2021 2021 2021 ...\n\nd1$BEAM.Year_first_ill &lt;- decomma(d1$BEAM.Year_first_ill)\nglimpse(d1$BEAM.Year_first_ill)\n\n num [1:339] 2021 2021 2021 2021 2021 ...\n\n\nI want to make sure that these categorical variables are actually categories\n\nd1$BEAM.Serotype &lt;- as.factor(d1$BEAM.Serotype)\nd1$BEAM.Food_category &lt;- as.factor(d1$BEAM.Food_category)\nskim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n339\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n2\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nBEAM.Year_range\n0\n1\n9\n9\n0\n3\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nBEAM.Food_category\n0\n1\nFALSE\n4\nChi: 108, Por: 102, Bee: 79, Tur: 50\n\n\nBEAM.Serotype\n0\n1\nFALSE\n36\nI 4: 23, Bra: 21, Mue: 21, Ent: 20\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nBEAM.Year_first_ill\n0\n1\n2021.61\n0.71\n2021\n2021\n2021\n2022\n2023\n▇▁▅▁▂\n\n\nBEAM.No_of_illnesses\n0\n1\n5.75\n23.54\n0\n0\n0\n0\n181\n▇▁▁▁▁\n\n\nBEAM.No_of_outbreaks\n0\n1\n0.19\n0.58\n0\n0\n0\n0\n4\n▇▁▁▁▁\n\n\nBEAM.Year\n0\n1\n2022.27\n0.75\n2021\n2022\n2022\n2023\n2023\n▃▁▆▁▇\n\n\nBEAM.Running_total_by_year_range\n0\n1\n38.68\n100.92\n0\n0\n0\n29\n679\n▇▁▁▁▁\n\n\n\n\nsummary(d1)\n\n BEAM.Food_category BEAM.Year_first_ill        BEAM.Serotype\n Beef   : 79        Min.   :2021        I 4,[5],12:i:-: 23  \n Chicken:108        1st Qu.:2021        Braenderup    : 21  \n Pork   :102        Median :2021        Muenchen      : 21  \n Turkey : 50        Mean   :2022        Enteritidis   : 20  \n                    3rd Qu.:2022        Typhimurium   : 19  \n                    Max.   :2023        Newport       : 18  \n                                        (Other)       :217  \n BEAM.No_of_illnesses BEAM.No_of_outbreaks   BEAM.Year    BEAM.Year_range   \n Min.   :  0.000      Min.   :0.0000       Min.   :2021   Length:339        \n 1st Qu.:  0.000      1st Qu.:0.0000       1st Qu.:2022   Class :character  \n Median :  0.000      Median :0.0000       Median :2022   Mode  :character  \n Mean   :  5.752      Mean   :0.1888       Mean   :2022                     \n 3rd Qu.:  0.000      3rd Qu.:0.0000       3rd Qu.:2023                     \n Max.   :181.000      Max.   :4.0000       Max.   :2023                     \n                                                                            \n BEAM.Running_total_by_year_range\n Min.   :  0.00                  \n 1st Qu.:  0.00                  \n Median :  0.00                  \n Mean   : 38.68                  \n 3rd Qu.: 29.00                  \n Max.   :679.00                  \n                                 \n\n\nI can now see that the most common serovars are monophasic Typhimurium (I 4,5,12,:i:-), Braenderup, Muenchen, Enteritidis, Typhimurium, and Newport.\nThis just leaves year range as something that should maybe be fixed. This one is tricky though, because each outbreak is going to have a separate year range. Also given how I filtered the data by year first ill this column may not be helpful.\nI want to know what commodities are associated with my top 6 serovars\n\nd2 &lt;- subset(d1, (BEAM.Serotype == \"Typhimurium\" | BEAM.Serotype == \"Braenderup\" | BEAM.Serotype == \"Muenchen\" | BEAM.Serotype == \"Newport\" | BEAM.Serotype == \"I 4,[5],12:i:-\"))\nsummary(d2)\n\n BEAM.Food_category BEAM.Year_first_ill        BEAM.Serotype\n Beef   :30         Min.   :2021        I 4,[5],12:i:-:23   \n Chicken:25         1st Qu.:2021        Braenderup    :21   \n Pork   :30         Median :2021        Muenchen      :21   \n Turkey :17         Mean   :2022        Typhimurium   :19   \n                    3rd Qu.:2022        Newport       :18   \n                    Max.   :2023        Adelaide      : 0   \n                                        (Other)       : 0   \n BEAM.No_of_illnesses BEAM.No_of_outbreaks   BEAM.Year    BEAM.Year_range   \n Min.   : 0.000       Min.   :0.0000       Min.   :2021   Length:102        \n 1st Qu.: 0.000       1st Qu.:0.0000       1st Qu.:2022   Class :character  \n Median : 0.000       Median :0.0000       Median :2022   Mode  :character  \n Mean   : 7.088       Mean   :0.2549       Mean   :2022                     \n 3rd Qu.: 0.000       3rd Qu.:0.0000       3rd Qu.:2023                     \n Max.   :81.000       Max.   :2.0000       Max.   :2023                     \n                                                                            \n BEAM.Running_total_by_year_range\n Min.   :  0.00                  \n 1st Qu.:  0.00                  \n Median :  0.00                  \n Mean   : 48.62                  \n 3rd Qu.: 80.00                  \n Max.   :551.00                  \n                                 \n\np1 &lt;- d2 %&gt;% ggplot(aes(x=BEAM.Food_category)) + geom_bar()\nplot(p1)\n\n\n\n\n\n\n\np2 &lt;- d2 %&gt;% ggplot(aes(x=BEAM.Serotype)) + geom_bar()\nplot(p2)\n\n\n\n\n\n\n\np3 &lt;- d2 %&gt;% ggplot(aes(fill=BEAM.Serotype, x=BEAM.Food_category)) + geom_bar()\nplot(p3)\n\n\n\n\n\n\n\n\nThis gets counts of these top commodities and the top serovars, then proportion of each commodity that responds to each serovar!\n\nThis section is contributed by Rebecca Basta\nAI prompt used: “Write R code to generate synthetic outbreak data similar in structure to CDC BEAM Salmonella dataset with 339 rows, 10 columns, and categorical + count variables.”\n\nset.seed(123)  # reproducibility\n\n\n# Number of observations similar to original\nn &lt;- 339\n\n# Create synthetic dataset\nsynthetic_data &lt;- data.frame(\n  Food_category = sample(\n    c(\"Chicken\", \"Beef\", \"Pork\", \"Eggs\", \"Vegetables\", \n      \"Fruit\", \"Seafood\", \"Dairy\", \"Turkey\"),\n    n, replace = TRUE\n  ),\n  \n  Serotype = sample(\n    paste(\"Serotype\", 1:36),\n    n, replace = TRUE\n  ),\n  \n  Year_first_ill = sample(2021:2024, n, replace = TRUE),\n  \n  Year = sample(2021:2024, n, replace = TRUE),\n  \n  No_of_illnesses = rpois(n, lambda = 25),\n  \n  No_of_outbreaks = rpois(n, lambda = 3)\n)\n\n# Running total by year range\nsynthetic_data &lt;- synthetic_data %&gt;%\n  arrange(Year) %&gt;%\n  mutate(Running_total_by_year_range = cumsum(No_of_illnesses))\n\nglimpse(synthetic_data)\n\nRows: 339\nColumns: 7\n$ Food_category               &lt;chr&gt; \"Beef\", \"Pork\", \"Seafood\", \"Pork\", \"Vegeta…\n$ Serotype                    &lt;chr&gt; \"Serotype 18\", \"Serotype 8\", \"Serotype 32\"…\n$ Year_first_ill              &lt;int&gt; 2021, 2021, 2021, 2023, 2021, 2024, 2022, …\n$ Year                        &lt;int&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, …\n$ No_of_illnesses             &lt;int&gt; 19, 28, 26, 16, 28, 25, 25, 28, 19, 18, 28…\n$ No_of_outbreaks             &lt;int&gt; 2, 7, 4, 1, 5, 3, 4, 1, 3, 4, 2, 4, 2, 0, …\n$ Running_total_by_year_range &lt;int&gt; 19, 47, 73, 89, 117, 142, 167, 195, 214, 2…\n\nsummary(synthetic_data)\n\n Food_category        Serotype         Year_first_ill      Year     \n Length:339         Length:339         Min.   :2021   Min.   :2021  \n Class :character   Class :character   1st Qu.:2021   1st Qu.:2022  \n Mode  :character   Mode  :character   Median :2023   Median :2023  \n                                       Mean   :2022   Mean   :2023  \n                                       3rd Qu.:2023   3rd Qu.:2023  \n                                       Max.   :2024   Max.   :2024  \n No_of_illnesses No_of_outbreaks Running_total_by_year_range\n Min.   :12.00   Min.   :0.000   Min.   :  19               \n 1st Qu.:21.00   1st Qu.:2.000   1st Qu.:2079               \n Median :24.00   Median :3.000   Median :4153               \n Mean   :24.59   Mean   :3.006   Mean   :4157               \n 3rd Qu.:28.00   3rd Qu.:4.000   3rd Qu.:6268               \n Max.   :41.00   Max.   :8.000   Max.   :8336               \n\n\n\n#renaming the serotypes from my synthetic data, so the plots can have the correct axis names\n#Before I did this, the plots were blank. I asked AI why they were blank and it was because the variable names didn't match, which is why I recoded them.\nsynthetic_data &lt;- synthetic_data %&gt;%\n  mutate(\n    Serotype = recode(\n      Serotype,\n      \"Serotype 1\" = \"Typhimurium\",\n      \"Serotype 2\" = \"Braenderup\",\n      \"Serotype 3\" = \"Muenchen\",\n      \"Serotype 4\" = \"Newport\",\n      \"Serotype 5\" = \"I 4,[5],12:i:-\"\n    )\n  )\n\n\n#Created a subset for the plots to have the same plots\nplot_subset &lt;- subset(\n  synthetic_data,\n  Food_category %in% c(\"Beef\", \"Chicken\", \"Pork\", \"Turkey\") &\n  Serotype %in% c(\n    \"Typhimurium\",\n    \"Braenderup\",\n    \"Muenchen\",\n    \"Newport\",\n    \"I 4,[5],12:i:-\"\n  )\n)\n\nPlots\n\np1 &lt;- ggplot(plot_subset, aes(x = Food_category)) +\n  geom_bar() +\n  labs(x = \"Food_category (synthetic data)\", y = \"count\")\np1\n\n\n\n\n\n\n\np2 &lt;- ggplot(plot_subset, aes(x = Serotype)) +\n  geom_bar() +\n  labs(x = \"Serotype (synthetic data)\", y = \"count\")\np2\n\n\n\n\n\n\n\np3 &lt;- ggplot(plot_subset, aes(x = Food_category, fill = Serotype)) +\n  geom_bar() +\n  labs(x = \"Food_category\", y = \"count\", fill = \"Serotype\")\np3\n\n\n\n\n\n\n\n\nThey synthetic data is a little different then the orginal data because the food catergory and serotype are random in the synthetic data. Other then that, the synthetic data and orginal data are the same. They both include 339 rows, 10 columns, and the same variables."
  }
]